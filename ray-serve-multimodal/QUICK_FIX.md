# üö® Quick Fix Guide - Single GPU Node

## Problem Summary

B·∫°n ƒëang ch·∫°y tr√™n node c√≥ **1 GPU** nh∆∞ng Ray LLM's vLLM engine t·ª± ƒë·ªông t·∫°o placement groups y√™u c·∫ßu nhi·ªÅu GPU h∆°n.

### Resource Request Breakdown:
```
Required per model:
  - Actor bundle: {"CPU": 1.0, "GPU": 0.45}
  - Engine bundle: {"GPU": 1.0}  ‚Üê vLLM t·ª± ƒë·ªông t·∫°o
  Total: 1.45 GPU ‚ùå

Available: 1.0 GPU ‚ùå
```

## ‚úÖ Solutions

### Option 1: Deploy Only ONE Model (Recommended for 1 GPU)

Edit `multi_model_config.yaml` - comment out model th·ª© 2:

```yaml
applications:
  - name: "falcon3-1b-instruct-app"
    # ... keep this

  # - name: "falcon-h1-0.5b-instruct-app"  ‚Üê Comment out
  #   ... comment all of this
```

Then run:
```bash
python3 app_v5.py multi_model_config.yaml
```

###Option 2: Use Simpler Deployment (No vLLM Placement Groups)

Th·ª≠ config ƒë∆°n gi·∫£n h∆°n m√† t√¥i ƒë√£ t·∫°o:

```bash
python3 app_v5.py multi_model_config_simple.yaml
```

Config n√†y:
- D√πng `num_gpus` thay v√¨ `ray_actor_options`
- Gi·∫£m resources: 0.4 GPU per replica
- C√≥ th·ªÉ ch·∫°y 2 replicas tr√™n 1 GPU

### Option 3: Add More GPU Nodes

N·∫øu c·∫ßn ch·∫°y nhi·ªÅu models, add th√™m nodes v√†o cluster:

```bash
# On another machine with GPU:
ray start --address='<head-node-ip>:6379'
```

### Option 4: Sequential Deployment (Backup Plan)

N·∫øu v·∫´n kh√¥ng ƒë∆∞·ª£c, quay l·∫°i `app_v4.py`:

```bash
# Deploy model 1
python3 app_v4.py config_model1_only.yaml

# Wait for it to finish, then deploy model 2
python3 app_v4.py config_model2_only.yaml
```

## üîß Debugging Commands

### Check available resources:
```bash
ray status
```

Look for:
```
Resources
---------------------------------------------------------------
Total Usage:
 X/4.0 CPU
 Y/1.0 GPU  ‚Üê Should show available GPU
```

### Check Serve status:
```bash
# In Python:
from ray import serve
print(serve.status())
```

### Shutdown and retry:
```bash
# Shutdown all deployments
python3 -c "from ray import serve; import ray; ray.init(); serve.shutdown()"

# Try again
python3 app_v5.py multi_model_config_simple.yaml
```

## üìù Working Config for 1 GPU Node

Create `single_model_config.yaml`:

```yaml
applications:
  - name: "falcon3-1b-app"
    import_path: "ray.serve.llm:build_openai_app"
    route_prefix: "/v1"
    args:
      llm_configs:
        - model_loading_config:
            model_id: "falcon3-1b"
            model_source: "tiiuae/Falcon3-1B-Instruct"
          deployment_config:
            name: "falcon3-1b"
            num_cpus: 1
            num_gpus: 0.9  # Use most of the GPU
            autoscaling_config:
              min_replicas: 1
              max_replicas: 1  # Only 1 replica on 1 GPU
          engine_kwargs:
            dtype: "float16"
            gpu_memory_utilization: 0.9
            max_model_len: 8192
            enforce_eager: true
            trust_remote_code: true
```

Run:
```bash
python3 app_v5.py single_model_config.yaml
```

## üéØ Best Practice for Your Setup

**With 1 GPU node:**
- ‚úÖ Deploy 1 large model OR
- ‚úÖ Deploy 2 small models sequentially OR  
- ‚úÖ Use simple config without placement groups

**Don't:**
- ‚ùå Try to deploy 2 models concurrently with vLLM engine
- ‚ùå Use `tensor_parallel_size > 0` on single GPU
- ‚ùå Set `ray_actor_options` with vLLM (causes placement group issues)

## üöÄ Next Steps

1. **Try Option 1** (single model) first
2. If that works, try `multi_model_config_simple.yaml`
3. If you need concurrent multi-model, add more GPU nodes

Let me know which option you want to try!
